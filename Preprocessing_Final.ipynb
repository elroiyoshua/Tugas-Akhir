{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBQnEHcFySvB",
        "outputId": "d48db6d8-fde1-42e9-e84e-5b70e992643f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlp-id in /usr/local/lib/python3.10/dist-packages (0.1.15.0)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (1.2.2)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (3.8.1)\n",
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (3.2)\n",
            "Requirement already satisfied: pytest==7.3.1 in /usr/local/lib/python3.10/dist-packages (from nlp-id) (7.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->nlp-id) (4.66.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.3.1->nlp-id) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->nlp-id) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install nlp-id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U5xoAsN1GfJ",
        "outputId": "1468411e-969e-4c66-c005-d135cd7446b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: indoNLP in /usr/local/lib/python3.10/dist-packages (0.3.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install indoNLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv5uYo2fFhL7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from indoNLP.preprocessing import replace_slang\n",
        "from indoNLP.preprocessing import emoji_to_words\n",
        "# from emoticon import emoticon\n",
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0aLLM_8nGaHc",
        "outputId": "b628f027-6eca-4ed5-fa7d-0f09981c06cc"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"data_gabung_bu.csv\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "chnjGtWLk8ze",
        "outputId": "3d94ded4-45a8-419a-8868-82d7ce976b4c"
      },
      "outputs": [],
      "source": [
        "df = df2.head()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LY1Vd4vNkLN"
      },
      "source": [
        "## Case Folding\n",
        "Mengubah semua huruf kapital menjadi huruf non kapital"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "AseungPsNjeJ",
        "outputId": "c22f1d6f-60be-4252-855b-4604bc93661f"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: x.lower())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHa1WnbXAKMH"
      },
      "source": [
        "# Stopword Removal\n",
        "Menghapius semua kata yang tidak bermakna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjgBxp-5ANnE",
        "outputId": "f2fa09c4-5417-4174-bced-8ff099a3c244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqN1paGFH7zC",
        "outputId": "81b161ba-74a8-48f1-c52e-5a1a8a49c5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "760\n"
          ]
        }
      ],
      "source": [
        "set_stopwords = set(stopwords.words('indonesian'))\n",
        "set_stopwords.update([\"deh\", \"nya\", \"wkwkw\"])\n",
        "print(len(set_stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XILQpTHPJQA8"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in set_stopwords]\n",
        "    return ' '.join(filtered_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "u5A91cwtIPPx",
        "outputId": "f842d8a0-e6e9-4987-b92b-0743697f702c"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: remove_stopwords(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t021zAxZSmb",
        "outputId": "a5f81151-fd55-4890-cefe-0fb237820826"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTaEefWs1USP"
      },
      "source": [
        "# Replace Bahasa Alay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "-DnQvjZr1iFQ",
        "outputId": "310a5e76-81f7-46ad-df81-b54e647b2827"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: replace_slang(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4twkiF1ZMzv"
      },
      "source": [
        "# Mengubah Emoji dan Emoticon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "tfSaaMBjZrtW",
        "outputId": "81461f7d-a288-462a-8376-a97eef971db1"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: emoji_to_words(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn8msmC20Gq6"
      },
      "outputs": [],
      "source": [
        "EMOTICONS = {\n",
        "    u\":‑\\)\":\"senyum bahagia\",\n",
        "    u\":\\)\":\"senyum bahagia\",\n",
        "    u\":-\\]\":\"senyum bahagia\",\n",
        "    u\":\\]\":\"senyum bahagia\",\n",
        "    u\":-3\":\"senyum bahagia\",\n",
        "    u\":3\":\"senyum bahagia\",\n",
        "    u\":->\":\"senyum bahagia\",\n",
        "    u\":>\":\"senyum bahagia\",\n",
        "    u\"8-\\)\":\"senyum bahagia\",\n",
        "    u\":o\\)\":\"senyum bahagia\",\n",
        "    u\":-\\}\":\"senyum bahagia\",\n",
        "    u\":\\}\":\"senyum bahagia\",\n",
        "    u\":‑\\)\":\"senyum bahagia\",\n",
        "    u\":c\\)\":\"senyum bahagia\",\n",
        "    u\":\\^\\)\":\"senyum bahagia\",\n",
        "    u\"=\\]\":\"senyum bahagia\",\n",
        "    u\"=\\)\":\"senyum bahagia\",\n",
        "    u\":‑D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\":D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"8‑D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"8D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"X‑D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"XD\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"=D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"=3\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\"B\\^D\":\"tertawa, senyum besar, atau tawa dengan kacamata\",\n",
        "    u\":-\\)\\)\":\"sangat bahagia\",\n",
        "    u\":‑\\(\":\"marah, sedih, atau cemberut\",\n",
        "    u\":-\\(\":\"marah, sedih, atau cemberut\",\n",
        "    u\":\\(\":\"marah, sedih, atau cemberut\",\n",
        "    u\":‑c\":\"marah, sedih, atau cemberut\",\n",
        "    u\":c\":\"marah, sedih, atau cemberut\",\n",
        "    u\":‑<\":\"marah, sedih, atau cemberut\",\n",
        "    u\":<\":\"marah, sedih, atau cemberut\",\n",
        "    u\":‑\\[\":\"marah, sedih, atau cemberut\",\n",
        "    u\":\\[\":\"marah, sedih, atau cemberut\",\n",
        "    u\":-\\|\\|\":\"marah, sedih, atau cemberut\",\n",
        "    u\">:\\[\":\"marah, sedih, atau cemberut\",\n",
        "    u\":\\{\":\"marah, sedih, atau cemberut\",\n",
        "    u\":@\":\"marah, sedih, atau cemberut\",\n",
        "    u\">:\\(\":\"marah, sedih, atau cemberut\",\n",
        "    u\":'‑\\(\":\"menangis\",\n",
        "    u\":'\\(\":\"menangis\",\n",
        "    u\":'‑\\)\":\"tangisan bahagia\",\n",
        "    u\":'\\)\":\"tangisan bahagia\",\n",
        "    u\"D‑':\":\"ketakutan\",\n",
        "    u\"D:<\":\"jijik\",\n",
        "    u\"D:\":\"sedih\",\n",
        "    u\"D8\":\"kekecewaan besar\",\n",
        "    u\"D;\":\"kekecewaan besar\",\n",
        "    u\"D=\":\"kekecewaan besar\",\n",
        "    u\"DX\":\"kekecewaan besar\",\n",
        "    u\":‑O\":\"terkejut\",\n",
        "    u\":O\":\"terkejut\",\n",
        "    u\":‑o\":\"terkejut\",\n",
        "    u\":o\":\"terkejut\",\n",
        "    u\":-0\":\"terkejut\",\n",
        "    u\"8‑0\":\"menguap\",\n",
        "    u\">:O\":\"menguap\",\n",
        "    u\":-\\*\":\"cium\",\n",
        "    u\":\\*\":\"cium\",\n",
        "    u\":X\":\"cium\",\n",
        "    u\";‑\\)\":\"berkedip atau senyum tersenyum\",\n",
        "    u\";\\)\":\"berkedip atau senyum tersenyum\",\n",
        "    u\"\\*-\\)\":\"berkedip atau senyum tersenyum\",\n",
        "    u\"\\*\\)\":\"berkedip atau senyum tersenyum\",\n",
        "    u\";‑\\]\":\"berkedip atau senyum tersenyum\",\n",
        "    u\";\\]\":\"berkedip atau senyum tersenyum\",\n",
        "    u\";\\^\\)\":\"berkedip atau senyum tersenyum\",\n",
        "    u\":‑,\":\"berkedip atau senyum tersenyum\",\n",
        "    u\";D\":\"berkedip atau senyum tersenyum\",\n",
        "    u\":‑P\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\":P\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\"X‑P\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\"XP\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\":‑Þ\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\":Þ\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\":b\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\"d:\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\"=p\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\">:P\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\":‑/\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":/\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":-[.]\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\">:[(\\\\\\)]\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\">:/\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":[(\\\\\\)]\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\"=/\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\"=[(\\\\\\)]\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":L\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\"=L\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":S\":\"skeptis, kesal, bingung, ragu-ragu, atau ragu-ragu\",\n",
        "    u\":‑\\|\":\"muka datar\",\n",
        "    u\":\\|\":\"muka datar\",\n",
        "    u\":$\":\"malu atau merah\",\n",
        "    u\":‑x\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\":x\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\":‑#\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\":#\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\":‑&\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\":&\":\"bibir tertutup atau memakai kawat gigi atau tergagap\",\n",
        "    u\"O:‑\\)\":\"malaikat, santo atau yang polos\",\n",
        "    u\"O:\\)\":\"malaikat, santo atau yang polos\",\n",
        "    u\"0:‑3\":\"malaikat, santo atau yang polos\",\n",
        "    u\"0:3\":\"malaikat, santo atau yang polos\",\n",
        "    u\"0:‑\\)\":\"malaikat, santo atau yang polos\",\n",
        "    u\"0:\\)\":\"malaikat, santo atau yang polos\",\n",
        "    u\":‑b\":\"menjulurkan lidah, nakal, bermain-main, atau meniupkan raspberry\",\n",
        "    u\"0;\\^\\)\":\"malaikat, santo atau yang polos\",\n",
        "    u\">:‑\\)\":\"jahat atau setan\",\n",
        "    u\">:\\)\":\"jahat atau setan\",\n",
        "    u\"\\}:‑\\)\":\"jahat atau setan\",\n",
        "    u\"\\}:\\)\":\"jahat atau setan\",\n",
        "    u\"3:‑\\)\":\"jahat atau setan\",\n",
        "    u\"3:\\)\":\"jahat atau setan\",\n",
        "    u\">;\\)\":\"jahat atau setan\",\n",
        "    u\"\\|;‑\\)\":\"keren\",\n",
        "    u\"\\|‑O\":\"bosan\",\n",
        "    u\":‑J\":\"bercanda\",\n",
        "    u\"#‑\\)\":\"pesta sepanjang malam\",\n",
        "    u\"%‑\\)\":\"mabuk atau bingung\",\n",
        "    u\"%\\)\":\"mabuk atau bingung\",\n",
        "    u\":-###..\":\"sedang sakit\",\n",
        "    u\":###..\":\"sedang sakit\",\n",
        "    u\"<:‑\\|\":\"dump\",\n",
        "    u\"\\(>_<\\)\":\"sulit\",\n",
        "    u\"\\(>_<\\)>\":\"sulit\",\n",
        "    u\"\\(';'\\)\":\"bayi\",\n",
        "    u\"\\(\\^\\^>``\":\"gugup atau Malu atau Sulit atau Malu atau Keringat\",\n",
        "    u\"\\(\\^_\\^;\\)\":\"gugup atau Malu atau Sulit atau Malu atau Keringat\",\n",
        "    u\"\\(-_-;\\)\":\"gugup atau Malu atau Sulit atau Malu atau Keringat\",\n",
        "    u\"\\(~_~;\\) \\(・\\.・;\\)\":\"gugup atau Malu atau Sulit atau Malu atau Keringat\",\n",
        "    u\"\\(-_-\\)zzz\":\"tidur\",\n",
        "    u\"\\(\\^_-\\)\":\"berkedip\",\n",
        "    u\"\\(\\(\\+_\\+\\)\\)\":\"bingung\",\n",
        "    u\"\\(\\+o\\+\\)\":\"bingung\",\n",
        "    u\"\\(o\\|o\\)\":\"ultraman\",\n",
        "    u\"\\^_\\^\":\"gembira\",\n",
        "    u\"\\(\\^_\\^\\)/\":\"gembira\",\n",
        "    u\"\\(\\^O\\^\\)／\":\"gembira\",\n",
        "    u\"\\(\\^o\\^\\)／\":\"gembira\",\n",
        "    u\"\\(__\\)\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"_\\(\\._\\.\\)_\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"<\\(_ _\\)>\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"<m\\(__\\)m>\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"m\\(__\\)m\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"m\\(_ _\\)m\":\"tunduk sebagai tanda penghormatan atau dogeza untuk permintaan maaf\",\n",
        "    u\"\\('_'\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(/_;\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(T_T\\) \\(;_;\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(;_;\":\"sedih atau menangis\",\n",
        "    u\"\\(;_:\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(;O;\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(:_;\\)\":\"sedih atau menangis\",\n",
        "    u\"\\(ToT\\)\":\"sedih atau menangis\",\n",
        "    u\";_;\":\"sedih atau menangis\",\n",
        "    u\";-;\":\"sedih atau menangis\",\n",
        "    u\";n;\":\"sedih atau menangis\",\n",
        "    u\";;\":\"sedih atau menangis\",\n",
        "    u\"Q\\.Q\":\"sedih atau menangis\",\n",
        "    u\"T\\.T\":\"sedih atau menangis\",\n",
        "    u\"QQ\":\"sedih atau menangis\",\n",
        "    u\"Q_Q\":\"sedih atau menangis\",\n",
        "    u\"\\(-\\.-\\)\":\"malu\",\n",
        "    u\"\\(-_-\\)\":\"malu\",\n",
        "    u\"\\(一一\\)\":\"malu\",\n",
        "    u\"\\(；一_一\\)\":\"malu\",\n",
        "    u\"\\(=_=\\)\":\"capek\",\n",
        "    u\"\\(=\\^\\·\\^=\\)\":\"kucing\",\n",
        "    u\"\\(=\\^\\·\\·\\^=\\)\":\"kucing\",\n",
        "        u\"=_\\^=\": \"kucing\",\n",
        "    u\"\\(\\.\\.\\)\": \"melihat ke bawah\",\n",
        "    u\"\\(\\._\\.\\)\": \"melihat ke bawah\",\n",
        "    u\"\\^m\\^\": \"tertawa sambil menutupi mulut dengan tangan\",\n",
        "    u\"\\(\\・\\・?\": \"bingung\",\n",
        "    u\"\\(?_?\\)\": \"bingung\",\n",
        "    u\">\\^_\\^<\": \"tertawa biasa\",\n",
        "    u\"<\\^!\\^>\": \"tertawa biasa\",\n",
        "    u\"\\^/\\^\": \"tertawa biasa\",\n",
        "    u\"\\（\\*\\^_\\^\\*）\": \"tertawa biasa\",\n",
        "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(^\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^\\.\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^_\\^\\.\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^_\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^J\\^\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\*\\^\\.\\^\\*\\)\": \"tertawa biasa\",\n",
        "    u\"\\(\\^—\\^\\）\": \"tertawa biasa\",\n",
        "    u\"\\(#\\^\\.\\^#\\)\": \"tertawa biasa\",\n",
        "    u\"\\（\\^—\\^\\）\": \"melambai\",\n",
        "    u\"\\(;_;\\)/~~~\": \"melambai\",\n",
        "    u\"\\(\\^\\.\\^\\)/~~~\": \"melambai\",\n",
        "    u\"\\(-_-\\)/~~~ \\($\\·\\·\\)/~~~\": \"melambai\",\n",
        "    u\"\\(T_T\\)/~~~\": \"melambai\",\n",
        "    u\"\\(ToT\\)/~~~\": \"melambai\",\n",
        "    u\"\\(\\*\\^0\\^\\*\\)\": \"sangat bersemangat\",\n",
        "    u\"\\(\\*_\\*\\)\": \"terkesan\",\n",
        "    u\"\\(\\*_\\*;\": \"terkesan\",\n",
        "    u\"\\(\\+_\\+\\) \\(@_@\\)\": \"terkesan\",\n",
        "    u\"\\(\\*\\^\\^\\)v\": \"tertawa, ceria\",\n",
        "    u\"\\(\\^_\\^\\)v\": \"tertawa, ceria\",\n",
        "    u\"\\(\\(d[-_-]b\\)\\)\": \"headphone, mendengarkan musik\",\n",
        "    u'\\(-\"-\\)': \"cemas\",\n",
        "    u\"\\(ーー;\\)\": \"cemas\",\n",
        "    u\"\\(\\^0_0\\^\\)\": \"kacamata\",\n",
        "    u\"\\(\\＾ｖ\\＾\\)\": \"bahagia\",\n",
        "    u\"\\(\\＾ｕ\\＾\\)\": \"bahagia\",\n",
        "    u\"\\(\\^\\)o\\(\\^\\)\": \"bahagia\",\n",
        "    u\"\\(\\^O\\^\\)\": \"bahagia\",\n",
        "    u\"\\(\\^o\\^\\)\": \"bahagia\",\n",
        "    u\"\\)\\^o\\^\\(\": \"bahagia\",\n",
        "    u\":O o_O\": \"terkejut\",\n",
        "    u\"o_0\": \"terkejut\",\n",
        "    u\"o\\.O\": \"terkejut\",\n",
        "    u\"\\(o\\.o\\)\": \"terkejut\",\n",
        "    u\"oO\": \"terkejut\",\n",
        "    u\"\\(\\*￣m￣\\)\": \"tidak puas\",\n",
        "    u\"\\(‘A`\\)\": \"diabaikan atau Kecewa\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tFbKLVxWnsmA",
        "outputId": "4e0f8dee-be1d-4ba1-bc0e-cd20ec5d9524"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Kocak lu ya senyum_bahagia'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "    return text\n",
        "\n",
        "text = \"Kocak lu ya :)\"\n",
        "convert_emoticons(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Cjv8OkEhYGSP",
        "outputId": "d664fe5c-d4c5-49ad-b946-a065d26895ce"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: convert_emoticons(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mT-s64AGgn"
      },
      "source": [
        "# Cleansing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7yjAZzA9LJ-"
      },
      "outputs": [],
      "source": [
        "# Penghilangan karakter spesial\n",
        "def remove_special_char(text):\n",
        "    text = text.replace('\\\\t', \" \").replace('\\\\n', \" \").replace('\\\\u', \" \").replace('\\\\', \"\")\n",
        "    text = text.encode('ascii', 'replace').decode('ascii')\n",
        "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
        "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
        "\n",
        "# Penghilangan angka\n",
        "def delNum(text):\n",
        "    return re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "# Mengganti \"_\" dengan spasi\n",
        "def chng_(text):\n",
        "    return text.replace(\"_\", \" \") #Tanya Bu Warih\n",
        "\n",
        "# Penghilangan tanda baca\n",
        "def delPunct(text):\n",
        "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "# Penghilangan strip\n",
        "def delWlt(text):\n",
        "    return text.strip()\n",
        "\n",
        "# Penghilangan white space\n",
        "def delWmt(text):\n",
        "    return re.sub('\\s+', ' ', text)\n",
        "\n",
        "# Penghilangan kata dengan 1 karakter\n",
        "def delSingle_char(text):\n",
        "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
        "\n",
        "\n",
        "def cleansing(text):\n",
        " text = remove_special_char(text)\n",
        " text = delNum(text)\n",
        " text = chng_(text) #Tergantung\n",
        " text = delPunct(text)\n",
        " text = delWlt(text)\n",
        " text = delWmt(text)\n",
        " text = delSingle_char(text)\n",
        " return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "td1vxASIGkhX",
        "outputId": "eb9e74cc-3f17-4f8e-bf05-23fc83bbd46c"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: cleansing(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWdWl-uGqaZ_"
      },
      "source": [
        "# Lemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0nfqA-1qfW_"
      },
      "outputs": [],
      "source": [
        "lemmatizer = Lemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "e27Y9Hagy9z_",
        "outputId": "b413ef02-eac3-4054-8105-ab2acd325f37"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: lemmatizer.lemmatize(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gE3VVkFLWGp"
      },
      "source": [
        "# Tokenization\n",
        "membuat token setiap katanya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_buvu2-dMCGP",
        "outputId": "7c7e68da-9884-4169-b20e-f90ed4a02a84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdGwXjaLY6V"
      },
      "outputs": [],
      "source": [
        "def tokenization(text):\n",
        "  return word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "I63aanarLcw5",
        "outputId": "7f9bfd0c-7497-4183-d6cc-6864f6afbf2f"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: tokenization(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMv7Q4mPk8zm"
      },
      "source": [
        "# Mengubah typo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMBKKxjVk8zm",
        "outputId": "2f9ca112-1af0-4e9b-e9af-cad513056123"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNW1yGXik8zm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "with open('idwiki.txt', 'r', encoding='utf-8') as file:\n",
        "    WORDS = Counter(file.read().split())\n",
        "\n",
        "def checkWord(kata):\n",
        "    if isinstance(kata, list):\n",
        "        return [checkWord(word) for word in kata]\n",
        "    elif kata not in WORDS:\n",
        "        return correction(kata)\n",
        "    else:\n",
        "        return kata\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    # \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word):\n",
        "    # \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word):\n",
        "    # \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words):\n",
        "    # \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    # \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)] # [('', 'kemarin'), ('k', 'emarin'), ('ke', 'marin'), dst]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R] # ['emarin', 'kmarin', 'kearin', dst]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1] # ['ekmarin', 'kmearin', 'keamrin', dst]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters] # ['aemarin', 'bemarin', 'cemarin', dst]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters] # ['akemarin', 'bkemarin', 'ckemarin', dst]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word):\n",
        "    # \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "8Iu_Vo56k8zm",
        "outputId": "67a3c937-059c-4036-9c2a-8a6047a098b0"
      },
      "outputs": [],
      "source": [
        "df['full_text'] = df['full_text'].apply(lambda x: checkWord(x) if isinstance(x, (str, list)) else x)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iapgJMZ2UTZs"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iyhy5mvfgA0t",
        "outputId": "63c0a76f-3ad2-414f-d248-ea343e9ad556"
      },
      "outputs": [],
      "source": [
        "df_final = df[['full_text','username']]\n",
        "df_final"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
